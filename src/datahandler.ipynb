{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9243135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting yfinance\n",
      "  Downloading yfinance-0.2.55-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: pandas>=1.3.0 in c:\\users\\riche\\onedrive\\documents\\umh25\\.venv\\lib\\site-packages (from yfinance) (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.16.5 in c:\\users\\riche\\onedrive\\documents\\umh25\\.venv\\lib\\site-packages (from yfinance) (2.2.4)\n",
      "Collecting requests>=2.31 (from yfinance)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting multitasking>=0.0.7 (from yfinance)\n",
      "  Downloading multitasking-0.0.11-py3-none-any.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in c:\\users\\riche\\onedrive\\documents\\umh25\\.venv\\lib\\site-packages (from yfinance) (4.3.7)\n",
      "Requirement already satisfied: pytz>=2022.5 in c:\\users\\riche\\onedrive\\documents\\umh25\\.venv\\lib\\site-packages (from yfinance) (2025.2)\n",
      "Collecting frozendict>=2.3.4 (from yfinance)\n",
      "  Downloading frozendict-2.4.6-py312-none-any.whl.metadata (23 kB)\n",
      "Collecting peewee>=3.16.2 (from yfinance)\n",
      "  Downloading peewee-3.17.9.tar.gz (3.0 MB)\n",
      "     ---------------------------------------- 0.0/3.0 MB ? eta -:--:--\n",
      "     ------------- -------------------------- 1.0/3.0 MB 8.5 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 2.6/3.0 MB 7.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 3.0/3.0 MB 7.1 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting beautifulsoup4>=4.11.1 (from yfinance)\n",
      "  Downloading beautifulsoup4-4.13.4-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4>=4.11.1->yfinance)\n",
      "  Downloading soupsieve-2.6-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting typing-extensions>=4.0.0 (from beautifulsoup4>=4.11.1->yfinance)\n",
      "  Downloading typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\riche\\onedrive\\documents\\umh25\\.venv\\lib\\site-packages (from pandas>=1.3.0->yfinance) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\riche\\onedrive\\documents\\umh25\\.venv\\lib\\site-packages (from pandas>=1.3.0->yfinance) (2025.2)\n",
      "Collecting charset-normalizer<4,>=2 (from requests>=2.31->yfinance)\n",
      "  Downloading charset_normalizer-3.4.1-cp312-cp312-win_amd64.whl.metadata (36 kB)\n",
      "Collecting idna<4,>=2.5 (from requests>=2.31->yfinance)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.31->yfinance)\n",
      "  Downloading urllib3-2.4.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests>=2.31->yfinance)\n",
      "  Downloading certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\riche\\onedrive\\documents\\umh25\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->yfinance) (1.17.0)\n",
      "Downloading yfinance-0.2.55-py2.py3-none-any.whl (109 kB)\n",
      "Downloading beautifulsoup4-4.13.4-py3-none-any.whl (187 kB)\n",
      "Downloading frozendict-2.4.6-py312-none-any.whl (16 kB)\n",
      "Downloading multitasking-0.0.11-py3-none-any.whl (8.5 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "Downloading charset_normalizer-3.4.1-cp312-cp312-win_amd64.whl (102 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading soupsieve-2.6-py3-none-any.whl (36 kB)\n",
      "Downloading typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
      "Downloading urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
      "Building wheels for collected packages: peewee\n",
      "  Building wheel for peewee (pyproject.toml): started\n",
      "  Building wheel for peewee (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for peewee: filename=peewee-3.17.9-py3-none-any.whl size=139127 sha256=d75997f5b62bf10353660516bc56062c1238a8804d9aadf035116cc90dd514e3\n",
      "  Stored in directory: c:\\users\\riche\\appdata\\local\\pip\\cache\\wheels\\43\\ef\\2d\\2c51d496bf084945ffdf838b4cc8767b8ba1cc20eb41588831\n",
      "Successfully built peewee\n",
      "Installing collected packages: peewee, multitasking, urllib3, typing-extensions, soupsieve, idna, frozendict, charset-normalizer, certifi, requests, beautifulsoup4, yfinance\n",
      "Successfully installed beautifulsoup4-4.13.4 certifi-2025.1.31 charset-normalizer-3.4.1 frozendict-2.4.6 idna-3.10 multitasking-0.0.11 peewee-3.17.9 requests-2.32.3 soupsieve-2.6 typing-extensions-4.13.2 urllib3-2.4.0 yfinance-0.2.55\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90fe5fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dotenv\n",
      "  Downloading dotenv-0.9.9-py2.py3-none-any.whl.metadata (279 bytes)\n",
      "Collecting python-dotenv (from dotenv)\n",
      "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Downloading dotenv-0.9.9-py2.py3-none-any.whl (1.9 kB)\n",
      "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: python-dotenv, dotenv\n",
      "Successfully installed dotenv-0.9.9 python-dotenv-1.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b930f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "class BaseDataHandler:\n",
    "    def __init__(self, \n",
    "             symbol: str, \n",
    "             start_time: datetime, \n",
    "             end_time: datetime,\n",
    "             limit: int = 100000,\n",
    "             flatten: bool = True,\n",
    "             window: str = \"hour\"):\n",
    "        self.symbol = symbol\n",
    "        self.start_dt = start_time\n",
    "        self.end_dt = end_time\n",
    "        self.start_time = self.convert_to_unix_ms(start_time)\n",
    "        self.end_time = self.convert_to_unix_ms(end_time)\n",
    "\n",
    "        # Default values\n",
    "        self.limit = limit\n",
    "        self.flatten = flatten\n",
    "        self.window = window\n",
    "\n",
    "        # Data containers\n",
    "        self.raw_data: pd.DataFrame = pd.DataFrame()\n",
    "        self.processed_data: pd.DataFrame = pd.DataFrame()\n",
    "\n",
    "        # Fetch OHLC\n",
    "        self.fetch_yfinance_data()\n",
    "\n",
    "        # Fetch funding rate\n",
    "        funding_params = {\n",
    "            \"exchange\": \"binance\",\n",
    "            \"window\": \"hour\",\n",
    "            \"start_time\": self.start_time,\n",
    "            \"end_time\": self.end_time,\n",
    "            \"flatten\": \"true\",\n",
    "            # \"limit\": 2\n",
    "        }\n",
    "\n",
    "        # Derive log return, volatility\n",
    "        self.preprocess()\n",
    "\n",
    "    def convert_to_unix_ms(self, dt: datetime) -> int:\n",
    "        return int(dt.timestamp() * 1000)\n",
    "\n",
    "    def load_from_disc(self, path: str):\n",
    "        self.raw_data = pd.read_csv(path)\n",
    "\n",
    "    def fetch_yfinance_data(self):\n",
    "        interval = self.window if self.window in ['1m', '2m', '5m', '15m', '30m', '1h', '90m', '1d'] else '1h'\n",
    "        data = yf.download(\n",
    "            self.symbol,\n",
    "            start=self.start_dt.strftime('%Y-%m-%d'),\n",
    "            end=self.end_dt.strftime('%Y-%m-%d'),\n",
    "            interval=interval,\n",
    "            progress=False\n",
    "        )\n",
    "\n",
    "        data.rename(columns={\n",
    "            'Open': 'open', \n",
    "            'High': 'high', \n",
    "            'Low': 'low', \n",
    "            'Close': 'close', \n",
    "            'Adj Close': 'adj_close', \n",
    "            'Volume': 'volume'\n",
    "        }, inplace=True)\n",
    "\n",
    "        data.dropna(inplace=True)\n",
    "        self.raw_data = data\n",
    "    \n",
    "    def get_processed_data(self) -> pd.DataFrame:\n",
    "        return self.processed_data\n",
    "\n",
    "    def preprocess(self):\n",
    "        df = self.raw_data\n",
    "        df.sort_index(inplace=True)\n",
    "        df.fillna(method='ffill', inplace=True)\n",
    "        \n",
    "        # Compute log return using close price\n",
    "        df[\"log_returns\"] = np.log(df[\"close\"] / df[\"close\"].shift(1))\n",
    "        df.dropna(inplace=True)  # Drop NaN values caused by the shift operation\n",
    "        \n",
    "        # Compute rolling volatility (standard deviation of log returns)\n",
    "        df[\"volatility_10\"] = df[\"log_returns\"].rolling(10).std()\n",
    "        df[\"vol_adj_returns\"] = df[\"log_returns\"] / df[\"volatility_10\"]\n",
    "\n",
    "        # Compute Indicators and Add to DataFrame\n",
    "        df[\"EMA_50\"] = self.compute_ema(df, period=50)\n",
    "        df[\"EMA_200\"] = self.compute_ema_200(df, period=200)\n",
    "        df[\"RSI_14\"] = self.compute_rsi(df, period=14)\n",
    "        df[\"MACD\"], df[\"MACD_Signal\"] = self.compute_macd(df)\n",
    "        df[\"ATR_14\"] = self.compute_atr(df, period=14)\n",
    "        df[\"SAR\"] = self.compute_sar(df)\n",
    "        df[\"SLOPE_14\"] = self.compute_slope(df, period=14)\n",
    "        df[\"ADX_14\"] = self.compute_adx(df, period=14)\n",
    "        df[\"OBV\"] = self.compute_obv_vectorized(df)\n",
    "\n",
    "        # Fill any NaNs from rolling calculations\n",
    "        df.fillna(0, inplace=True)\n",
    "        self.processed_data = df\n",
    "\n",
    "    # Moving Averages: EMA 50 & EMA 200\n",
    "    def compute_ema(self, df, column=\"close\", period=50):\n",
    "        return df[column].ewm(span=period, adjust=False).mean()\n",
    "\n",
    "    def compute_ema_200(self, df, column=\"close\", period=200):\n",
    "        return df[column].ewm(span=period, adjust=False).mean()\n",
    "    \n",
    "    # Momentum Indicators: RSI & MACD\n",
    "    def compute_rsi(self, df, column=\"close\", period=14):\n",
    "        delta = df[column].diff()\n",
    "        gain = delta.clip(lower=0)\n",
    "        loss = -delta.clip(upper=0)\n",
    "\n",
    "        avg_gain = gain.rolling(window=period).mean()\n",
    "        avg_loss = loss.rolling(window=period).mean()\n",
    "\n",
    "        rs = avg_gain / avg_loss\n",
    "        rsi = 100 - (100 / (1 + rs))\n",
    "        return rsi\n",
    "\n",
    "    def compute_macd(self, df, column=\"close\", short_period=12, long_period=26, signal_period=9):\n",
    "        short_ema = df[column].ewm(span=short_period, adjust=False).mean()\n",
    "        long_ema = df[column].ewm(span=long_period, adjust=False).mean()\n",
    "        macd_line = short_ema - long_ema\n",
    "        signal_line = macd_line.ewm(span=signal_period, adjust=False).mean()\n",
    "        return macd_line, signal_line\n",
    "\n",
    "\n",
    "    # Volatility Indicator: ATR\n",
    "    def compute_atr(self, df, period=14):\n",
    "        tr = np.maximum(df[\"high\"] - df[\"low\"],\n",
    "                        np.maximum(abs(df[\"high\"] - df[\"close\"].shift()),\n",
    "                                    abs(df[\"low\"] - df[\"close\"].shift())))\n",
    "        return tr.rolling(window=period).mean()\n",
    "\n",
    "    # Trend Indicators: SAR, Slope & ADX\n",
    "    def compute_slope(self, df, column=\"close\", period=14):\n",
    "        return df[column].diff(period) / period\n",
    "\n",
    "    def compute_sar(self, df, acceleration=0.02, maximum=0.2):\n",
    "        high = df[\"high\"].values\n",
    "        low = df[\"low\"].values\n",
    "        close = df[\"close\"].values\n",
    "\n",
    "        sar = np.zeros(len(df))\n",
    "        trend = 1  # 1 for uptrend, -1 for downtrend\n",
    "        af = acceleration\n",
    "        ep = high[0]  # extreme point\n",
    "        sar[0] = low[0]  # initial SAR value\n",
    "        \n",
    "        for i in range(1, len(df)):\n",
    "            prev_sar = sar[i - 1]\n",
    "            if trend == 1:\n",
    "                sar[i] = prev_sar + af * (ep - prev_sar)\n",
    "                if low[i] < sar[i]:\n",
    "                    trend = -1\n",
    "                    sar[i] = ep\n",
    "                    ep = low[i]\n",
    "                    af = acceleration\n",
    "                else:\n",
    "                    if high[i] > ep:\n",
    "                        ep = high[i]\n",
    "                        af = min(af + acceleration, maximum)\n",
    "            else:\n",
    "                sar[i] = prev_sar - af * (prev_sar - ep)\n",
    "                if high[i] > sar[i]:\n",
    "                    trend = 1\n",
    "                    sar[i] = ep\n",
    "                    ep = high[i]\n",
    "                    af = acceleration\n",
    "                else:\n",
    "                    if low[i] < ep:\n",
    "                        ep = low[i]\n",
    "                        af = min(af + acceleration, maximum)\n",
    "\n",
    "        return sar\n",
    "\n",
    "    def compute_adx(self, df, period=14):\n",
    "        plus_dm = np.maximum(df[\"high\"].diff(), 0)\n",
    "        minus_dm = np.maximum(-df[\"low\"].diff(), 0)\n",
    "        tr = np.maximum(df[\"high\"] - df[\"low\"],\n",
    "                        np.maximum(abs(df[\"high\"] - df[\"close\"].shift()),\n",
    "                                    abs(df[\"low\"] - df[\"close\"].shift())))\n",
    "        plus_di = 100 * (plus_dm.rolling(window=period).mean() / tr.rolling(window=period).mean())\n",
    "        minus_di = 100 * (minus_dm.rolling(window=period).mean() / tr.rolling(window=period).mean())\n",
    "        dx = 100 * np.abs(plus_di - minus_di) / (plus_di + minus_di)\n",
    "        return dx.rolling(window=period).mean()\n",
    "\n",
    "    # Volume Indicator: OBV\n",
    "    def compute_obv_vectorized(self, df):\n",
    "        direction = np.sign(df[\"close\"].diff()).fillna(0)\n",
    "        return (direction * df[\"volume\"]).cumsum()\n",
    "    \n",
    "    def export(self, path: str):\n",
    "        # Save the processed data to the specified path with the symbol in the filename\n",
    "        self.processed_data.to_csv(f\"{path}/{self.symbol}_data.csv\")\n",
    "        print(f\"Data exported to {path}/{self.symbol}_data.csv\")\n",
    "\n",
    "# Test the BaseDataHandler class\n",
    "handler = BaseDataHandler(symbol='BTC-USD',\n",
    "                          start_time=datetime(2025, 1, 1),\n",
    "                          end_time=datetime(2025, 4, 16),\n",
    "                          window=\"hour\")\n",
    "handler.export(\"/Users/pohsharon/Downloads/UMH\")\n",
    "print(handler.processed_data.tail())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
